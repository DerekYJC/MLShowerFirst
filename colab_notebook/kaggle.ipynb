{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Q1PLylen19Bn",
        "colab_type": "code",
        "outputId": "0a8c5a48-9198-4155-d2ae-83d539d55eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import imageio\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3eDfYSDq2BZr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFGZL9IES8Eb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 500\n",
        "\n",
        "\n",
        "test_path = '/content/gdrive/Team Drives/kaggle/data/test.zip'\n",
        "train_path = '/content/gdrive/Team Drives/kaggle/data/train.zip'\n",
        "\n",
        "# get training data info\n",
        "\n",
        "with ZipFile(train_path, 'r') as trainf:\n",
        "    train_set = pd.DataFrame({'infol': trainf.infolist()})\n",
        "\n",
        "train_set['id'] = train_set.infol.map(lambda x: x.filename.split('.')[0])\n",
        "labels = pd.read_csv(\n",
        "    '/content/gdrive/Team Drives/kaggle/data/train_labels.csv')\n",
        "train_set = train_set.merge(labels, on='id')\n",
        "\n",
        "with ZipFile(test_path, 'r') as testf:\n",
        "    test_set = pd.DataFrame({'infol': testf.infolist()})\n",
        "\n",
        "test_set['id'] = test_set.infol.map(lambda x: x.filename.split('.')[0])\n",
        "\n",
        "testing_set=train_set[219000:]\n",
        "train_set=train_set[:219000]    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TlsZAwdNubHY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_x = tf.placeholder(dtype=tf.float32, shape=[None, 96, 96, 3])\n",
        "input_y = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
        "input_x_nor=input_x/128-1\n",
        "\n",
        "input_x_ =tf.keras.layers.Input(input_x.shape[1:])\n",
        "\n",
        "conv1 = tf.keras.layers.Conv2D(\n",
        "    filters=50,\n",
        "    kernel_size=(3, 3),\n",
        "    padding='same',\n",
        "    activation=tf.nn.relu)(input_x_)\n",
        "p1 = tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=(2, 2))(conv1)\n",
        "\n",
        "conv2 = tf.keras.layers.Conv2D(\n",
        "    filters=100,\n",
        "    kernel_size=(3, 3),\n",
        "    padding='same',\n",
        "    activation=tf.nn.relu)(p1)\n",
        "p2 = tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=(2, 2))(conv2)\n",
        "\n",
        "conv3 = tf.keras.layers.Conv2D(\n",
        "    filters=100,\n",
        "    kernel_size=(3, 3),\n",
        "    padding='same',\n",
        "    activation=tf.nn.relu)(p2)\n",
        "p3 = tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=(2, 2))(conv3)\n",
        "\n",
        "f1 = tf.keras.layers.Flatten()(p3)\n",
        "d1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)(f1)\n",
        "\n",
        "y_ = tf.keras.layers.Dense(units=1, activation='sigmoid')(d1)\n",
        "\n",
        "md=tf.keras.Model(inputs=input_x_,outputs=y_)\n",
        "y_pred=md(input_x_nor)\n",
        "\n",
        "loss = tf.losses.mean_squared_error(labels=input_y, predictions=y_pred)\n",
        "opt = tf.train.AdamOptimizer(learning_rate=5e-4)\n",
        "train = opt.minimize(loss,var_list=md.trainable_variables)\n",
        "\n",
        "err=tf.math.abs(y_pred-input_y)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6UxuWj9HTFKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(zip_path, _df):\n",
        "\n",
        "    X = np.zeros([0, 96, 96, 3])\n",
        "    with ZipFile(zip_path, 'r') as zp:\n",
        "        for i in _df.index:\n",
        "            with zp.open(_df.infol[i]) as imagefile:\n",
        "                img = Image.open(imagefile)\n",
        "                # img.show()\n",
        "                X = np.concatenate((X, [np.array(img)]), axis=0)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ue99hGg_uuCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def training(x_, y_):\n",
        "    t, l = sess.run([train, loss], feed_dict={input_x: x_, input_y: y_})\n",
        "    print(l)\n",
        "\n",
        "def acc(x_,y_):\n",
        "    er=sess.run(err,feed_dict={input_x:x_,input_y:y_})\n",
        "    result = (np.where(er<0.5,1.,0.))\n",
        "    acc=np.mean(result)\n",
        "    return acc\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p6ZfQPDsvs1N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xfsvya_VuzTc",
        "colab_type": "code",
        "outputId": "228689d2-ccc0-4a42-e623-42dd47637fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size=500\n",
        "batch_n = int(len(train_set)/batch_size)\n",
        "\n",
        "xtb=load_data(train_path,testing_set)\n",
        "ytb=np.array(testing_set.label.values.reshape([-1,1]))\n",
        "\n",
        "for epo in range(10):\n",
        "    print('in epo:', epo)\n",
        "    for i in range(batch_n):\n",
        "        print(i,'/',batch_n)\n",
        "\n",
        "        xx = train_set[i*batch_size:(i+1)*batch_size]\n",
        "        x_batch = load_data(train_path, xx)\n",
        "        y_batch = np.array(\n",
        "            train_set.label[i*batch_size:(i+1)*batch_size]).reshape([-1, 1])\n",
        "        training(x_batch, y_batch)\n",
        "        \n",
        "        \n",
        "        if i%10 ==0:\n",
        "            print('acc:',acc(xtb,ytb))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in epo: 0\n",
            "0 / 438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-a2ad796ca10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         y_batch = np.array(\n\u001b[1;32m     15\u001b[0m             train_set.label[i*batch_size:(i+1)*batch_size]).reshape([-1, 1])\n",
            "\u001b[0;32m<ipython-input-58-9966cb6223a6>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(zip_path, _df)\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;31m# img.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "83s-M-FnxtUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(md,'/content/gdrive/Team Drives/kaggle/models/md_0128_0011_acc87')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}